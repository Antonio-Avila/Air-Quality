---
title: "AQS"
author: "Antonio Avila"
date: "10/18/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(RAQSAPI)
library(keyring)
library(beepr)
library(usmap)
library(lubridate)
library(forecast)
library(plotly)
library(rjson)
library(forecast)
library(tseries)
library(quantmod)
```

## R Markdown

```{r enable AQS credentials, include = FALSE}
# key_set(service = 'AQSDatamart', username = 'aavila2802@gmail.com')

datamart_user <-  'aavila2802@gmail.com'
server <-  'AQSDatamart'
aqs_credentials(username = datamart_user, key_get(service = server, username = datamart_user))
```


```{r state codes, include = FALSE}

state_codes <- aqs_states()

```


```{r extract ozone data, include = FALSE}

# parameter 62104 is the max temp in a 24 Hr period
# parameter 62105 is the min temp in a 24 Hr period
# parameter 62106 is the temp diff in a 24 Hr period
# parameter 44201 is the ozone 
# parameter 42102 is carbon dioxide

# Working for the parameter code 45201 (benzine) but not for any other codes from the list above

# start_time = proc.time()
# ozone_texas <- aqs_sampledata_by_state(parameter = "44201",
#                                            bdate = as.Date("20200901",
#                                                            format="%Y%m%d"
#                                                            ),
#                                            edate = as.Date("20210901",
#                                                           format = "%Y%m%d"),
#                                            stateFIPS = "48"
#                                           )
# print("Time to Execute:")
# print(proc.time() - start_time)
# beep()

```


```{r import data and combine}

# ozone_texas_20_21 <- read_csv("ozone_texas_20_21.csv")
# ozone_texas_19_20 <- read_csv("ozone_texas_19_20.csv")
# ozone_texas_18_19 <- read_csv("ozone_texas_18_19.csv")
# ozone_texas_17_18 <- read_csv("ozone_texas_17_18.csv")
# 
# ozone_texas <- union(union(union(ozone_texas_17_18, ozone_texas_18_19), ozone_texas_19_20), ozone_texas_20_21)
# 
# write_csv(ozone_texas, "ozone_texas.csv")

ozone_texas <- read_csv("ozone_texas.csv")
ozone_texas["fips"] <- as.integer(ozone_texas$state_code) * 1000 + as.integer(ozone_texas$county_code)

```


```{r function for 8 hour ozone avg}


avg_8hr <- function(data){
  avgs = matrix(nrow = 24-8, ncol = 1)
  for(i in 1:(24-8)) { 
    avgs[i] = mean(data[i:(i+7)], na.rm = TRUE)
  }
  return(avgs)
}


max_8hr_avg <- function(data){
  max_avg = max(avg_8hr(data)) * 1000
  max_avg = trunc(max_avg)
  return(max_avg)
}


```


```{r verify with published data}
# Verified calculations with results from various days published by the Texas Commission on Environmental Quality
# 
# test_day <- ozone_texas %>% filter(date_local == "2019-10-02", site_number == "0416")
# test_day$sample_measurement %>% max_8hr_avg()

```


```{r find daily max avg per county}
daily_max_sites <- ozone_texas %>% 
  group_by(county, fips, site_number, date_local) %>% 
  summarize(max_8hr_avg = max_8hr_avg(sample_measurement))

daily_max_counties <- daily_max_sites %>%
  group_by(county, fips, date_local) %>% 
  summarise(county_max = max(max_8hr_avg, na.rm = TRUE))
```



```{r Harris county ozone lvl, include = FALSE}

# Normal gpplot, but working towards turning it into an interactive plot_ly plot 

# p <- daily_max_counties %>% filter(county == "Harris") %>% 
#   ggplot(aes(date_local, county_max)) + 
#     geom_line(aes(color = county_max)) + 
#     scale_color_gradient(low = "green", high = "red") +
#     geom_hline(yintercept = 70, color = "red") +
#     geom_smooth(method = "gam", se = FALSE) + 
#     ggtitle("Harris County Ozone levels 2017-2021") +
#     xlab("Date") +
#     ylab("Ozone 8-Hr Max (ppb)") +
#     annotate("text", x = as.Date("2018-01-01"), y = 71, label = "Unhealthy Level")
# p


p <- daily_max_counties %>% filter(county == "Harris") %>% 
  ggplot(aes(date_local, county_max)) + 
    geom_line(aes(color="8-Hr Max Avg Ozone")) + 
    geom_hline(yintercept = 70, color = "red") +
    geom_smooth(method = "gam", se = FALSE, aes(color = "Local Model")) + 
    geom_smooth(method = "lm", aes(color = "Trend"), se = FALSE) +
    ggtitle("Harris County Ozone levels 2017-2021") +
    xlab("Date") +
    ylab("Ozone 8-Hr Max (ppb)") +
    annotate("text", x = as.Date("2018-01-01"), y = 71, label = "Unhealthy Level") +
    scale_color_manual(name = "Legend", values = c("#69b3a2", "#00A9FF", "purple"))
ggplotly(p, dynamicTicks = TRUE) %>%  layout(hovermode = "x") %>% rangeslider()

ozone_lm <- lm(county_max ~., data = harris_county)
summary(ozone_lm)


# Some statistics
adf.test(harris_county$county_max, k =365)
Box.test(harris_county$county_max, type = "Ljung", lag = 365)

par(mfcol = c(2,1))
Acf(harris_county$county_max, lag.max = 720)
Pacf(harris_county$county_max, lag.max = 720)
par(mfcol = c(1,1))
```

Even though there is some variability throughout the time period in the daily, maximum 8-hour ozone levels, the plot suggests there may be a slight downward trend. Fitting a linear model to the time series data rejects this notion. The p-value for the coefficient corresponding to the date yields a value of 0.47, meaning the coefficient and thus variable is not statistically significant. There is no evidence to suggest a statistically significant decrease in ozone levels with time. Granted, this model cannot be used for anything other than determining a trend since it is a very poor fit for the data. The data is obviously non-linear with some seasonality sprinkled in there, which makes sense since ozone levels should increase during summer periods. 

Next, I will attempt to fit a model the data using a more appropriate method. The classical approach to time series data is to model it using an ARIMA model, or some variation of it, to forecast with it. 


```{r testing arima model}
# Tried to fit an arima model using the auto.arima function, knowing it wasn't going to perform well. But damn, wasn't expecting it to be this bad.

harris_county <- daily_max_counties %>% ungroup() %>% filter(county == "Harris") %>% select(date_local, county_max)
fit = auto.arima(harris_county$county_max)
fit
pred = forecast(fit, 100)
p <- ggplot(harris_county, aes(x = date_local)) +
  geom_line(aes(y = county_max, color = "blue")) + 
  geom_line(aes(y = pred$fitted, color = "red")) +
  scale_color_manual(name="Values",labels=c("Measured Values", "Predictions"), values=c("dodgerblue4", "firebrick4"))
ggplotly(p, dynamicTicks = TRUE) %>% layout(hovermode = "x")

p <- ggplot(harris_county, aes(x = date_local, y = pred$residuals)) +
  geom_line() +
  xlab("Date") + ylab("Residuals")
ggplotly(p, dynamicTicks = TRUE) %>% layout(hovermode = "x")


```


```{r arima model with differencing}

ozone_diff <- data.frame(date_local = harris_county$date_local[-1], diff = diff(harris_county$county_max))
ggplot(ozone_diff, aes(diff)) + geom_histogram()
ggplot(ozone_diff) + geom_line(aes(date_local, diff))

p <- ozone_diff %>% ggplot(aes(date_local, diff)) +
  geom_line(aes(color = "Difference")) +
      geom_smooth(aes(color = "Smoothing funciton")) +
      scale_color_manual(name = "legend", values = c("#69b3a2", "#00A9FF")) +
      xlab("Date") +
      ylab("Ozone Difference") +
      ggtitle("Ozone Daily Change")
ggplotly(p, dynamicTicks = TRUE) %>%  layout(hovermode = "x") 


t.test(ozone_diff$diff)
adf.test(ozone_diff$diff, k = 365)
# Box.test(ozone_diff$diff, type = "Ljung", lag = 365)

par(mfcol = c(2,1))
Acf(ozone_diff$diff, lag.max = 720)
Pacf(ozone_diff$diff, lag.max = 720)
par(mfcol = c(1,1))


# fit an arima model
fit = auto.arima(ozone_diff$diff)
fit
pred = forecast(fit, 100)
p <- ggplot(harris_county, aes(x = date_local)) +
  geom_line(aes(y = county_max, color = "blue")) + 
  geom_line(aes(y = c(78, pred$fitted + 78), color = "red")) +
  scale_color_manual(name="Values",labels=c("Measured Values", "Predictions"), values=c("dodgerblue4", "firebrick4"))
ggplotly(p, dynamicTicks = TRUE) %>% layout(hovermode = "x")

p <- ggplot(ozone_diff, aes(x = date_local, y = pred$residuals)) +
  geom_line() +
  xlab("Date") + ylab("Residuals")
ggplotly(p, dynamicTicks = TRUE) %>% layout(hovermode = "x")
```

Difference statistics are misleading. While hinting at stationarity and other wanteed atrributes in time series data, it performs awful and is no where near the actual values. 

Differencing the data yields some interesting results. Performing an Augmented Dickey-Fuller test shows the data is now stationary, but the Box-Ljung test suggests the 

Time series analysis relies around around the concept of the ideal scenario involving stationary data. Many of the results 



```{r adjusting for seasonality}

ozone_season <- data.frame(diff = diff(harris_county$county_max, lag = 365))
ggplot(ozone_season, aes(diff)) + geom_histogram()

p <- ozone_season %>% ggplot(aes(1:length(diff), diff)) +
      geom_line(aes(color = "Difference")) +
      geom_smooth(aes(color = "Smoothing funciton")) +
      scale_color_manual(name = "legend", values = c("#69b3a2", "#00A9FF")) +
      xlab("Date") +
      ylab("Ozone Difference") +
      ggtitle("Ozone Daily Change")
ggplotly(p, dynamicTicks = TRUE) %>%  layout(hovermode = "x") 



t.test(ozone_season$diff)
adf.test(ozone_season$diff, k = 365)
Box.test(ozone_season$diff, type = "Ljung")

par(mfcol = c(2,1))
Acf(ozone_season$diff, lag.max = 720)
Pacf(ozone_season$diff, lag.max = 720)
par(mfcol = c(1,1))

```


```{r}

p <- daily_max_counties %>% filter(date_local == "2020-05-01") %>% 
  plot_usmap(regions = "counties", include = "TX", data = ., values = "county_max") +
    scale_fill_gradient(low = "green", high = "red", labels = "high", breaks = 70)
ggplotly(p) 


daily_max_counties %>% filter(date_local == "2018-05-01") %>% 
  plot_usmap(regions = "counties", include = "TX", data = ., values = "county_max") +
    scale_fill_gradient(low = "green", high = "red",  labels = "high", breaks = 70)

```













```{r county average hourly}

# hourly_avg <- 

  head(ozone_texas) %>% group_by(county, date_local, time_local) %>% 
              summarise(date_time = as.POSIXct(paste(date_local, time_local), format = "%Y-%m-%d %H:%M"), 
                        hourly_avg = mean(sample_measurement, na.rm = TRUE) * 1000)
                                                                                                        


```



```{r}

hourly_avg %>% group_by(county, date_local) %>% filter(county == "Harris") %>% ggplot(aes(date)
                                                                                      
                                                                                      
```










